{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplot\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 180 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)  # image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model VGG16\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                         include_top=False,\n",
    "                                         weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(512, activation='relu')\n",
    "prediction_layer = tf.keras.layers.Dense(5, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 5, 5, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 14,979,909\n",
      "Trainable params: 14,979,909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.00001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "92/92 [==============================] - 86s 930ms/step - loss: 0.7716 - accuracy: 0.7197 - val_loss: 0.5238 - val_accuracy: 0.8120\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 24s 263ms/step - loss: 0.4100 - accuracy: 0.8522 - val_loss: 0.4031 - val_accuracy: 0.8474\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 24s 264ms/step - loss: 0.3133 - accuracy: 0.8835 - val_loss: 0.3857 - val_accuracy: 0.8610\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 24s 265ms/step - loss: 0.2384 - accuracy: 0.9203 - val_loss: 0.3609 - val_accuracy: 0.8638\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 24s 257ms/step - loss: 0.1846 - accuracy: 0.9370 - val_loss: 0.3459 - val_accuracy: 0.8747\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.1407 - accuracy: 0.9520 - val_loss: 0.4791 - val_accuracy: 0.8583\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 24s 264ms/step - loss: 0.1068 - accuracy: 0.9656 - val_loss: 0.3516 - val_accuracy: 0.8774\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 24s 262ms/step - loss: 0.0862 - accuracy: 0.9721 - val_loss: 0.3790 - val_accuracy: 0.8719\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.3582 - val_accuracy: 0.8883\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 24s 263ms/step - loss: 0.0552 - accuracy: 0.9840 - val_loss: 0.3748 - val_accuracy: 0.8883\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 24s 265ms/step - loss: 0.0410 - accuracy: 0.9908 - val_loss: 0.3822 - val_accuracy: 0.8747\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 24s 258ms/step - loss: 0.0365 - accuracy: 0.9898 - val_loss: 0.3855 - val_accuracy: 0.8910\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.0323 - accuracy: 0.9905 - val_loss: 0.3885 - val_accuracy: 0.8883\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.3716 - val_accuracy: 0.8910\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.0284 - accuracy: 0.9949 - val_loss: 0.4527 - val_accuracy: 0.8937\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.0332 - accuracy: 0.9925 - val_loss: 0.4318 - val_accuracy: 0.8910\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 23s 255ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 0.5620 - val_accuracy: 0.8719\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 23s 255ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.3985 - val_accuracy: 0.8910\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 24s 256ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.4588 - val_accuracy: 0.9046\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 24s 258ms/step - loss: 0.0342 - accuracy: 0.9939 - val_loss: 0.4213 - val_accuracy: 0.8992\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20   # 이번에는 이전보다 훨씬 빠르게 수렴되므로 5Epoch이면 충분합니다.\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1eb6d36942e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = 10\n",
    "loss0, accuracy0 = model.evaluate(test_batches, steps = test_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
